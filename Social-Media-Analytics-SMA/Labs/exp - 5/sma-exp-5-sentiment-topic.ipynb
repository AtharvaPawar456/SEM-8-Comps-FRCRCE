{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7553932,"sourceType":"datasetVersion","datasetId":4399595},{"sourceId":7735089,"sourceType":"datasetVersion","datasetId":4520338},{"sourceId":7735246,"sourceType":"datasetVersion","datasetId":4520451},{"sourceId":7809528,"sourceType":"datasetVersion","datasetId":4573942}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-10T17:48:54.984135Z","iopub.execute_input":"2024-03-10T17:48:54.984870Z","iopub.status.idle":"2024-03-10T17:48:55.000577Z","shell.execute_reply.started":"2024-03-10T17:48:54.984832Z","shell.execute_reply":"2024-03-10T17:48:54.999272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom gensim import corpora\nfrom gensim.models import LdaModel\nfrom gensim.models import CoherenceModel\nimport matplotlib.pyplot as plt","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/food-review-web-scrapped-data/google.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:56:32.224300Z","iopub.execute_input":"2024-03-10T17:56:32.225201Z","iopub.status.idle":"2024-03-10T17:56:32.275153Z","shell.execute_reply.started":"2024-03-10T17:56:32.225144Z","shell.execute_reply":"2024-03-10T17:56:32.273951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of columns to remove\n# columns_to_remove = ['WMbnJf href', 'lDY1rd src','TSUbDb', 'RvU3D href', 'A503be', 'dehysf', 'dmZI8b', 'PV7e7','k8MTF','k8MTF 42',  'k8MTF 43', 'k8MTF 46', 'k8MTF 47', 'k8MTF 48', 'k8MTF 49', 'k8MTF 51', 'QWOdjf 19','pi8uOe 17']\n\n# Drop specified columns\n# df = df.drop(columns=columns_to_remove)\ndf = df[['review-full-text']]\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:57:46.498518Z","iopub.execute_input":"2024-03-10T17:57:46.498991Z","iopub.status.idle":"2024-03-10T17:57:46.514597Z","shell.execute_reply.started":"2024-03-10T17:57:46.498954Z","shell.execute_reply":"2024-03-10T17:57:46.513391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# df = df.rename(columns={\n#     'NBa7we src': 'source',\n#     'd4r55': 'reviewer_name',\n#     'RfnDt': 'review_rating',\n# #     'eaLgGf': 'review_date',\n# #     'hCCjke': 'review_text',\n# #     'rsqaWe': 'review_likes',\n# #     'wiI7pd': 'response_text',\n# #     'w8nwRe': 'response_date',\n# #     'dSlJg': 'response_likes',\n# #     'znYl0': 'response_dislikes',\n# #     'dSlJg 2': 'response2_likes',\n# #     'znYl0 2': 'response2_dislikes',\n# #     'nM6d2c': 'response2_text',\n# #     'DZSIDd': 'response2_date',\n# #     'wiI7pd 2': 'response2_date',\n# #     'W8gobe': 'response2_text'\n# })","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:58:00.673683Z","iopub.execute_input":"2024-03-10T17:58:00.674139Z","iopub.status.idle":"2024-03-10T17:58:00.679040Z","shell.execute_reply.started":"2024-03-10T17:58:00.674105Z","shell.execute_reply":"2024-03-10T17:58:00.678209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(inplace=True)  # Drop rows with missing values","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:58:26.991772Z","iopub.execute_input":"2024-03-10T17:58:26.992225Z","iopub.status.idle":"2024-03-10T17:58:26.998913Z","shell.execute_reply.started":"2024-03-10T17:58:26.992194Z","shell.execute_reply":"2024-03-10T17:58:26.997965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from textblob import TextBlob\n\ndef get_sentiment(text):\n  analysis = TextBlob(text)\n  sentiment_score = analysis.sentiment.polarity\n  sentiment_category = \"positive\" if sentiment_score > 0 else \"negative\" if sentiment_score < 0 else \"neutral\"\n  return sentiment_score, sentiment_category\n\ndf[\"sentiment_score\"], df[\"sentiment_category\"] = zip(*df[\"review-full-text\"].apply(get_sentiment))\n\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:58:50.835341Z","iopub.execute_input":"2024-03-10T17:58:50.835784Z","iopub.status.idle":"2024-03-10T17:58:50.945688Z","shell.execute_reply.started":"2024-03-10T17:58:50.835750Z","shell.execute_reply":"2024-03-10T17:58:50.944422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\nimport numpy as np\n\n# Combine all the text in the 'text' column\nall_text = df['review-full-text'].tolist()\n\n# Vectorize the text using CountVectorizer\nvectorizer = CountVectorizer(stop_words='english')\nX = vectorizer.fit_transform(all_text)\n\n# Perform Latent Dirichlet Allocation\nnum_topics = 5  # You can adjust the number of topics based on your requirements\nlda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\nlda.fit(X)\n\n# Function to get the top words for each topic\ndef get_top_words(model, feature_names, n_words=10):\n    topics = []\n    for topic_idx, topic in enumerate(model.components_):\n        top_words = [feature_names[i] for i in topic.argsort()[:-n_words - 1:-1]]\n        topics.append(top_words)\n    return topics\n\n# Get the feature names from the vectorizer\nfeature_names = vectorizer.get_feature_names_out()\n\n# Get the top words for each topic\ntopics = get_top_words(lda, feature_names)\n\n# Print the topics\nfor i, topic in enumerate(topics):\n    print(f\"Topic {i + 1}: {', '.join(topic)}\")\n\n# Assign topics to a new column 'topics_LDA'\ndf['topics_LDA'] = [topics[np.argmax(doc)] for doc in lda.transform(X)]\n\n# Print the DataFrame with the new 'topics_LDA' column\nprint(df[['review-full-text', 'topics_LDA']])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:59:20.694355Z","iopub.execute_input":"2024-03-10T17:59:20.694831Z","iopub.status.idle":"2024-03-10T17:59:20.767094Z","shell.execute_reply.started":"2024-03-10T17:59:20.694791Z","shell.execute_reply":"2024-03-10T17:59:20.766006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Topic_LDA for Row 3:\", df.loc[2, 'topics_LDA'])","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:59:34.480606Z","iopub.execute_input":"2024-03-10T17:59:34.481476Z","iopub.status.idle":"2024-03-10T17:59:34.490234Z","shell.execute_reply.started":"2024-03-10T17:59:34.481430Z","shell.execute_reply":"2024-03-10T17:59:34.488911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom nltk import FreqDist\nfrom nltk import bigrams\nimport seaborn as sns\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nimport nltk\nimport re\n\n# Download NLTK resources\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('vader_lexicon')","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:47:56.668496Z","iopub.execute_input":"2024-03-10T17:47:56.669923Z","iopub.status.idle":"2024-03-10T17:47:59.550935Z","shell.execute_reply.started":"2024-03-10T17:47:56.669881Z","shell.execute_reply":"2024-03-10T17:47:59.549588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the CSV file\nfile_path = \"/kaggle/input/ronaldos-tweets-insight-engagement-and-trends/cr_tweets.csv\"\ndf = pd.read_csv(file_path)\n\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T08:31:36.862401Z","iopub.execute_input":"2024-03-01T08:31:36.862749Z","iopub.status.idle":"2024-03-01T08:31:36.903394Z","shell.execute_reply.started":"2024-03-01T08:31:36.862722Z","shell.execute_reply":"2024-03-01T08:31:36.902819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T08:31:36.904312Z","iopub.execute_input":"2024-03-01T08:31:36.904871Z","iopub.status.idle":"2024-03-01T08:31:36.918024Z","shell.execute_reply.started":"2024-03-01T08:31:36.904842Z","shell.execute_reply":"2024-03-01T08:31:36.917216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove specified columns\ncolumns_to_remove = ['id', 'createdAt', 'retweetCount', 'replyCount', 'likeCount', 'quoteCount', 'bookmarkCount']\ndf = df.drop(columns=columns_to_remove, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T08:31:36.919685Z","iopub.execute_input":"2024-03-01T08:31:36.919911Z","iopub.status.idle":"2024-03-01T08:31:36.925258Z","shell.execute_reply.started":"2024-03-01T08:31:36.919892Z","shell.execute_reply":"2024-03-01T08:31:36.924539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T08:31:36.926460Z","iopub.execute_input":"2024-03-01T08:31:36.926782Z","iopub.status.idle":"2024-03-01T08:31:36.941360Z","shell.execute_reply.started":"2024-03-01T08:31:36.926757Z","shell.execute_reply":"2024-03-01T08:31:36.940468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Null Values Before Cleaning:\", df.isnull().sum())\ndf['text'] = df['text'].str.lower()\ndf = df.dropna()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T08:31:36.942886Z","iopub.execute_input":"2024-03-01T08:31:36.943172Z","iopub.status.idle":"2024-03-01T08:31:36.952111Z","shell.execute_reply.started":"2024-03-01T08:31:36.943146Z","shell.execute_reply":"2024-03-01T08:31:36.951229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T08:31:36.952935Z","iopub.execute_input":"2024-03-01T08:31:36.953136Z","iopub.status.idle":"2024-03-01T08:31:36.964184Z","shell.execute_reply.started":"2024-03-01T08:31:36.953117Z","shell.execute_reply":"2024-03-01T08:31:36.963521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove stop words and special characters\nstop_words = set(stopwords.words('english') + ['https', 'de', 'e', 'um'])\ndf['text'] = df['text'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word.lower() not in stop_words]))\ndf['text'] = df['text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T08:31:37.183629Z","iopub.execute_input":"2024-03-01T08:31:37.183961Z","iopub.status.idle":"2024-03-01T08:31:37.395029Z","shell.execute_reply.started":"2024-03-01T08:31:37.183937Z","shell.execute_reply":"2024-03-01T08:31:37.393856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sentiment analysis using NLTK's Vader\nsid = SentimentIntensityAnalyzer()\ndf['compound'] = df['text'].apply(lambda x: sid.polarity_scores(x)['compound'])\ndf['sentiment_label'] = df['compound'].apply(lambda x: 'positive' if x > 0 else 'negative' if x < 0 else 'neutral')\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T08:31:37.763224Z","iopub.execute_input":"2024-03-01T08:31:37.763517Z","iopub.status.idle":"2024-03-01T08:31:37.896260Z","shell.execute_reply.started":"2024-03-01T08:31:37.763481Z","shell.execute_reply":"2024-03-01T08:31:37.895513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['sentiment_label'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T08:31:38.493546Z","iopub.execute_input":"2024-03-01T08:31:38.493915Z","iopub.status.idle":"2024-03-01T08:31:38.501692Z","shell.execute_reply.started":"2024-03-01T08:31:38.493891Z","shell.execute_reply":"2024-03-01T08:31:38.500711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n# Combine all the text in the 'text' column\nall_text = ' '.join(df['text'])\n\n# Generate a word cloud\nwordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)\n\n# Plot the WordCloud image\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.title('Word Cloud for Tweets')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T08:31:39.614685Z","iopub.execute_input":"2024-03-01T08:31:39.614982Z","iopub.status.idle":"2024-03-01T08:31:40.592154Z","shell.execute_reply.started":"2024-03-01T08:31:39.614961Z","shell.execute_reply":"2024-03-01T08:31:40.591269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentiment_counts = df['sentiment_label'].value_counts()\n\n# Create a figure and two subplots\nfig, axs = plt.subplots(1, 2, figsize=(12, 6))\n\n# Plot the positive sentiment pie chart\naxs[0].pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=90, colors=['green', 'gray', 'gray'], wedgeprops=dict(width=0.3))\naxs[0].set_title('Sentiment Distribution')\n\n# Plot the negative sentiment pie chart\naxs[1].pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=90, colors=['gray', 'gray', 'red'], wedgeprops=dict(width=0.3))\n\n# Set the aspect ratio to be equal to ensure the pie charts are circular\naxs[0].set_aspect('equal')\naxs[1].set_aspect('equal')\n\n# Hide the y-axis on the second subplot\naxs[1].set_yticks([])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T08:31:44.268182Z","iopub.execute_input":"2024-03-01T08:31:44.268512Z","iopub.status.idle":"2024-03-01T08:31:44.477383Z","shell.execute_reply.started":"2024-03-01T08:31:44.268475Z","shell.execute_reply":"2024-03-01T08:31:44.476482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\n\n# Combine all the text in the 'text' column\nall_text = df['text'].tolist()\n\n# Vectorize the text using CountVectorizer\nvectorizer = CountVectorizer(stop_words='english')\nX = vectorizer.fit_transform(all_text)\n\n# Perform Latent Dirichlet Allocation\nnum_topics = 5  # You can adjust the number of topics based on your requirements\nlda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\nlda.fit(X)\n\n# Function to get the top words for each topic\ndef get_top_words(model, feature_names, n_words=10):\n    topics = []\n    for topic_idx, topic in enumerate(model.components_):\n        top_words = [feature_names[i] for i in topic.argsort()[:-n_words - 1:-1]]\n        topics.append(top_words)\n    return topics\n\n# Get the feature names from the vectorizer\nfeature_names = vectorizer.get_feature_names_out()\n\n# Get the top words for each topic\ntopics = get_top_words(lda, feature_names)\n\n# Print the topics\nfor i, topic in enumerate(topics):\n    print(f\"Topic {i + 1}: {', '.join(topic)}\")\n\n# Assign topics to a new column 'topics_LDA'\ndf['topics_LDA'] = [topics[np.argmax(doc)] for doc in lda.transform(X)]\n\n# Print the DataFrame with the new 'topics_LDA' column\nprint(df[['text', 'topics_LDA']])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T08:31:44.930836Z","iopub.execute_input":"2024-03-01T08:31:44.931145Z","iopub.status.idle":"2024-03-01T08:31:45.699699Z","shell.execute_reply.started":"2024-03-01T08:31:44.931122Z","shell.execute_reply":"2024-03-01T08:31:45.698712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T08:32:11.412756Z","iopub.execute_input":"2024-03-01T08:32:11.413052Z","iopub.status.idle":"2024-03-01T08:32:11.423511Z","shell.execute_reply.started":"2024-03-01T08:32:11.413029Z","shell.execute_reply":"2024-03-01T08:32:11.422789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the 'topics_LDA' column for row 3\nprint(\"Topic_LDA for Row 3:\", df.loc[2, 'topics_LDA'])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T08:32:11.602521Z","iopub.execute_input":"2024-03-01T08:32:11.603106Z","iopub.status.idle":"2024-03-01T08:32:11.607932Z","shell.execute_reply.started":"2024-03-01T08:32:11.603076Z","shell.execute_reply":"2024-03-01T08:32:11.607188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Audio Processing : Librosa","metadata":{}},{"cell_type":"code","source":"pip install librosa pydub SpeechRecognition","metadata":{"execution":{"iopub.status.busy":"2024-03-01T08:51:59.808954Z","iopub.execute_input":"2024-03-01T08:51:59.809275Z","iopub.status.idle":"2024-03-01T08:52:09.026038Z","shell.execute_reply.started":"2024-03-01T08:51:59.809244Z","shell.execute_reply":"2024-03-01T08:52:09.025370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import librosa\nimport librosa.display\nimport speech_recognition as sr\nfrom pydub import AudioSegment\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\nimport urllib.request\n\naudio_url = \"https://github.com/AtharvaPawar456/SEM-8-Comps-FRCRCE/raw/main/Social-Media-Analytics-SMA/Labs/exp%20-%205/Cristiano%20Ronaldo%20Motivational%20Speech%20%20CR7%20best%20advice%20for%20lifetime%20%20English%20Motivational%20Videos.mp4\"\n\n# audio_url = \"https://github.com/AtharvaPawar456/SEM-8-Comps-FRCRCE/blob/main/Social-Media-Analytics-SMA/Labs/exp%20-%205/ILTV%20News%20Flash%20-%20War%20Day%20146%20February%2029%202024.mp4\"\noutput_file = \"audio.mp4\"\n\n# Download the file\nurllib.request.urlretrieve(audio_url, output_file)\n\nprint(\"Audio file downloaded successfully.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:00:28.270437Z","iopub.execute_input":"2024-03-01T09:00:28.270784Z","iopub.status.idle":"2024-03-01T09:00:28.838947Z","shell.execute_reply.started":"2024-03-01T09:00:28.270738Z","shell.execute_reply":"2024-03-01T09:00:28.838136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the audio file using librosa\naudio_file_path = \"/kaggle/input/iltv-news-flash-war-day-146-february-29-2024/ILTV News Flash - War Day 146 February 29 2024.mp4\"\naudio, sr = librosa.load(audio_file_path, sr=None)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:02:36.207024Z","iopub.execute_input":"2024-03-01T09:02:36.207326Z","iopub.status.idle":"2024-03-01T09:02:36.844933Z","shell.execute_reply.started":"2024-03-01T09:02:36.207304Z","shell.execute_reply":"2024-03-01T09:02:36.844185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio, sr","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:02:38.080712Z","iopub.execute_input":"2024-03-01T09:02:38.081030Z","iopub.status.idle":"2024-03-01T09:02:38.086686Z","shell.execute_reply.started":"2024-03-01T09:02:38.081009Z","shell.execute_reply":"2024-03-01T09:02:38.085886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Audio Feature Extraction\nchroma_stft = librosa.feature.chroma_stft(y=audio, sr=sr)\nmfccs = librosa.feature.mfcc(y=audio, sr=sr)\nspectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\nspectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:02:38.095007Z","iopub.execute_input":"2024-03-01T09:02:38.095241Z","iopub.status.idle":"2024-03-01T09:02:39.750151Z","shell.execute_reply.started":"2024-03-01T09:02:38.095213Z","shell.execute_reply":"2024-03-01T09:02:39.749466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot Chroma Feature\nplt.figure(figsize=(12, 6))\nplt.subplot(3, 1, 1)\nlibrosa.display.specshow(chroma_stft, y_axis='chroma', x_axis='time')\nplt.title('Chroma Feature')\nplt.colorbar()\n\n# Plot MFCCs\nplt.subplot(3, 1, 2)\nlibrosa.display.specshow(mfccs, x_axis='time')\nplt.title('MFCCs')\nplt.colorbar()\n\n# Plot Spectral Centroid\nplt.subplot(3, 1, 3)\nplt.semilogy(spectral_centroid, label='Spectral Centroid', color='b')\nplt.ylabel('Hz')\nplt.title('Spectral Centroid')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:02:39.751433Z","iopub.execute_input":"2024-03-01T09:02:39.751806Z","iopub.status.idle":"2024-03-01T09:02:41.110066Z","shell.execute_reply.started":"2024-03-01T09:02:39.751785Z","shell.execute_reply":"2024-03-01T09:02:41.109274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Beat and Tempo Detection\ntempo, beat_frames = librosa.beat.beat_track(y=audio, sr=sr)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:02:41.110979Z","iopub.execute_input":"2024-03-01T09:02:41.111209Z","iopub.status.idle":"2024-03-01T09:02:42.181567Z","shell.execute_reply.started":"2024-03-01T09:02:41.111189Z","shell.execute_reply":"2024-03-01T09:02:42.180907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Plot Beat and Tempo\nbeat_times = librosa.frames_to_time(beat_frames, sr=sr)\n\nplt.figure(figsize=(12, 4))\n\n# Plot the waveform\nplt.plot(np.arange(len(audio)) / sr, audio, label='Waveform', alpha=0.5)\n\n# Plot the beat frames\nplt.vlines(beat_times, ymin=min(audio), ymax=max(audio), color='r', linestyle='dashed', label='Beat Frames')\n\nplt.xlabel('Time (s)')\nplt.ylabel('Amplitude')\nplt.title(f'Beat Detection (Tempo: {tempo:.2f} BPM)')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:02:42.183058Z","iopub.execute_input":"2024-03-01T09:02:42.183405Z","iopub.status.idle":"2024-03-01T09:02:47.492074Z","shell.execute_reply.started":"2024-03-01T09:02:42.183383Z","shell.execute_reply":"2024-03-01T09:02:47.491461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Music Visualization\nplt.figure(figsize=(12, 8))\n\nplt.subplot(3, 1, 1)\nlibrosa.display.waveshow(audio, sr=sr)\nplt.title('Waveform')\n\nplt.subplot(3, 1, 2)\nlibrosa.display.specshow(librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max), y_axis='log', x_axis='time')\nplt.title('Spectrogram')\n\nplt.subplot(3, 1, 3)\nlibrosa.display.specshow(chroma_stft, y_axis='chroma', x_axis='time')\nplt.title('Chromagram')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:02:47.492887Z","iopub.execute_input":"2024-03-01T09:02:47.493532Z","iopub.status.idle":"2024-03-01T09:02:56.352710Z","shell.execute_reply.started":"2024-03-01T09:02:47.493509Z","shell.execute_reply":"2024-03-01T09:02:56.351789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install moviepy","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:02:56.353749Z","iopub.execute_input":"2024-03-01T09:02:56.354130Z","iopub.status.idle":"2024-03-01T09:03:05.600568Z","shell.execute_reply.started":"2024-03-01T09:02:56.354109Z","shell.execute_reply":"2024-03-01T09:03:05.599358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pydub import AudioSegment\nimport speech_recognition as sr\nimport os\n\ndef convert_to_wav(input_file, output_file):\n    audio = AudioSegment.from_file(input_file, format=\"mp4\")\n    audio.export(output_file, format=\"wav\")\n\ndef split_audio(input_file, output_directory, chunk_size=7000):\n    audio = AudioSegment.from_wav(input_file)\n    num_chunks = len(audio) // chunk_size + 1\n\n    for i in range(num_chunks):\n        start_time = i * chunk_size\n        end_time = (i + 1) * chunk_size\n        chunk = audio[start_time:end_time]\n        chunk.export(os.path.join(output_directory, f\"chunk_{i+1}.wav\"), format=\"wav\")\n\ndef recognize_text_from_audio(input_file):\n    recognizer = sr.Recognizer()\n\n    with sr.AudioFile(input_file) as source:\n        audio_data = recognizer.record(source)\n        try:\n            text = recognizer.recognize_google(audio_data)\n            return text\n        except sr.UnknownValueError:\n            return \"Speech Recognition could not understand audio\"\n        except sr.RequestError as e:\n            return f\"Could not request results from Google Speech Recognition service; {e}\"\n\n# Convert to WAV\naudio_file_path_wav = \"/kaggle/working/audio.wav\"\nconvert_to_wav(audio_file_path, audio_file_path_wav)\n\n# Split into chunks\noutput_directory = \"/kaggle/working/chunks\"\nos.makedirs(output_directory, exist_ok=True)\nsplit_audio(audio_file_path_wav, output_directory)\n\nfinal_text = \"\"\nfinal_text_list = []\n\n# Recognize text from each chunk\nfor i, chunk_file in enumerate(os.listdir(output_directory)):\n    chunk_path = os.path.join(output_directory, chunk_file)\n    text = recognize_text_from_audio(chunk_path)\n    print(f\"Text from Chunk {i + 1}:\\n{text}\\n\")\n    final_text += \" \" + text\n    final_text_list.append(text)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:03:05.602523Z","iopub.execute_input":"2024-03-01T09:03:05.602895Z","iopub.status.idle":"2024-03-01T09:04:28.438457Z","shell.execute_reply.started":"2024-03-01T09:03:05.602861Z","shell.execute_reply":"2024-03-01T09:04:28.437766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Speech length : \", len(final_text))\nprint(\"\\nSpeech text   :\\n\",final_text)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:04:28.441128Z","iopub.execute_input":"2024-03-01T09:04:28.441550Z","iopub.status.idle":"2024-03-01T09:04:28.445519Z","shell.execute_reply.started":"2024-03-01T09:04:28.441522Z","shell.execute_reply":"2024-03-01T09:04:28.444711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate Word Cloud\nwordcloud = WordCloud(width=800, height=400, random_state=42, max_font_size=100, background_color='white').generate(final_text)\n\n# Display the Word Cloud using matplotlib\nplt.figure(figsize=(10, 6))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.title('Word Cloud for Final Text')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:04:28.446914Z","iopub.execute_input":"2024-03-01T09:04:28.447196Z","iopub.status.idle":"2024-03-01T09:04:29.216825Z","shell.execute_reply.started":"2024-03-01T09:04:28.447170Z","shell.execute_reply":"2024-03-01T09:04:29.215953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation, NMF\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Download NLTK resources\nnltk.download('vader_lexicon')\n\n# Example text for demonstration\n# final_text = \"Your final text goes here. It can be a combination of sentences or paragraphs.\"\n\n# Sentiment Analysis using NLTK's Vader\nsid = SentimentIntensityAnalyzer()\nsentiment_scores = sid.polarity_scores(final_text)\nsentiment_label = 'positive' if sentiment_scores['compound'] > 0 else 'negative' if sentiment_scores['compound'] < 0 else 'neutral'\n\nprint(\"Sentiment Analysis:\")\nprint(f\"Compound Sentiment Score: {sentiment_scores['compound']}\")\nprint(f\"Sentiment Label: {sentiment_label}\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:04:29.218003Z","iopub.execute_input":"2024-03-01T09:04:29.218238Z","iopub.status.idle":"2024-03-01T09:04:29.242301Z","shell.execute_reply.started":"2024-03-01T09:04:29.218217Z","shell.execute_reply":"2024-03-01T09:04:29.241533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Topic Modeling using Latent Dirichlet Allocation (LDA)\nvectorizer = CountVectorizer(stop_words='english')\nX = vectorizer.fit_transform([final_text])\n\nnum_topics_lda = 3  # Adjust the number of topics as needed\nlda = LatentDirichletAllocation(n_components=num_topics_lda, random_state=42)\nlda.fit(X)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:04:29.243305Z","iopub.execute_input":"2024-03-01T09:04:29.243585Z","iopub.status.idle":"2024-03-01T09:04:29.261154Z","shell.execute_reply.started":"2024-03-01T09:04:29.243563Z","shell.execute_reply":"2024-03-01T09:04:29.260254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Topic Modeling using Non-Negative Matrix Factorization (NMF)\nvectorizer_tfidf = TfidfVectorizer(stop_words='english')\nX_tfidf = vectorizer_tfidf.fit_transform([final_text])\n\nnum_topics_nmf = 3  # Adjust the number of topics as needed\nnmf = NMF(n_components=num_topics_nmf, random_state=42)\nnmf.fit(X_tfidf)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:04:29.262305Z","iopub.execute_input":"2024-03-01T09:04:29.262572Z","iopub.status.idle":"2024-03-01T09:04:29.275087Z","shell.execute_reply.started":"2024-03-01T09:04:29.262550Z","shell.execute_reply":"2024-03-01T09:04:29.274102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert sentiment scores to a Pandas DataFrame\nsentiment_df = pd.DataFrame(sentiment_scores, index=[0])\n\n# Visualization\nplt.figure(figsize=(15, 5))\n\n# Plot Sentiment Analysis\nplt.subplot(1, 3, 1)\nsns.barplot(data=sentiment_df, palette=\"viridis\")\nplt.title('Sentiment Analysis')\n\n# Plot LDA Topics\nplt.subplot(1, 3, 2)\nfor i, topic in enumerate(lda.components_):\n    plt.bar(range(len(vectorizer.get_feature_names_out())), topic, label=f'Topic {i + 1}', alpha=0.5)\nplt.xlabel('Word Index')\nplt.ylabel('Weight')\nplt.title('LDA Topics')\nplt.legend()\n\n# Plot NMF Topics\nplt.subplot(1, 3, 3)\nfor i, topic in enumerate(nmf.components_):\n    plt.bar(range(len(vectorizer_tfidf.get_feature_names_out())), topic, label=f'Topic {i + 1}', alpha=0.5)\nplt.xlabel('Word Index')\nplt.ylabel('Weight')\nplt.title('NMF Topics')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:04:29.277026Z","iopub.execute_input":"2024-03-01T09:04:29.278740Z","iopub.status.idle":"2024-03-01T09:04:32.363408Z","shell.execute_reply.started":"2024-03-01T09:04:29.278716Z","shell.execute_reply":"2024-03-01T09:04:32.362526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install gensim scikit-learn","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:04:32.365056Z","iopub.execute_input":"2024-03-01T09:04:32.365288Z","iopub.status.idle":"2024-03-01T09:04:41.575635Z","shell.execute_reply.started":"2024-03-01T09:04:32.365268Z","shell.execute_reply":"2024-03-01T09:04:41.574562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation, NMF\nfrom gensim.corpora.dictionary import Dictionary\nfrom gensim.models.ldamodel import LdaModel\nfrom gensim.models.nmf import Nmf\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Example final_text\n# final_text = \"Your final text goes here. It can be a combination of sentences or paragraphs.\"\n\n# Function to extract topics using Latent Dirichlet Allocation (LDA)\ndef get_lda_topics(text, num_topics=5):\n    vectorizer = CountVectorizer(stop_words='english')\n    X = vectorizer.fit_transform([text])\n\n    lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n    lda.fit(X)\n\n    words = vectorizer.get_feature_names_out()\n    topics = {}\n\n    for i, topic in enumerate(lda.components_):\n        top_words_idx = topic.argsort()[:-6:-1]  # Get indices of top 5 words for each topic\n        top_words = [words[idx] for idx in top_words_idx]\n        topics[f\"Topic {i + 1}\"] = {\n            \"Top Words\": top_words,\n            \"Score\": topic.sum()  # You can customize the score calculation as needed\n        }\n\n    return topics\n\n# Function to extract topics using Non-Negative Matrix Factorization (NMF)\ndef get_nmf_topics(text, num_topics=5):\n    vectorizer_tfidf = TfidfVectorizer(stop_words='english')\n    X_tfidf = vectorizer_tfidf.fit_transform([text])\n\n    nmf = NMF(n_components=num_topics, random_state=42)\n    nmf.fit(X_tfidf)\n\n    words = vectorizer_tfidf.get_feature_names_out()\n    topics = {}\n\n    for i, topic in enumerate(nmf.components_):\n        top_words_idx = topic.argsort()[:-6:-1]  # Get indices of top 5 words for each topic\n        top_words = [words[idx] for idx in top_words_idx]\n        topics[f\"Topic {i + 1}\"] = {\n            \"Top Words\": top_words,\n            \"Score\": topic.sum()  # You can customize the score calculation as needed\n        }\n\n    return topics\n\n# Get topics using LDA\nlda_topics = get_lda_topics(final_text)\n\n# Get topics using NMF\nnmf_topics = get_nmf_topics(final_text)\n\n# Combine topics from LDA and NMF\ncombined_topics = {**lda_topics, **nmf_topics}\n\n# Sort topics by score and print the top 5\ntop_5_topics = sorted(combined_topics.items(), key=lambda x: x[1]['Score'], reverse=True)[:5]\n\n\ntopic, details = top_5_topics[0]\nprint(f\"{topic}: {details['Top Words']}, Score: {details['Score']}\\n\\n\\n\")\n\n# Print top 5 topics\nprint(\"Top 5 Topics:\")\nfor topic, details in top_5_topics:\n    print(f\"\\t --- {topic}: {details['Top Words']}, Score: {details['Score']}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:09:41.679004Z","iopub.execute_input":"2024-03-01T09:09:41.679305Z","iopub.status.idle":"2024-03-01T09:09:41.703653Z","shell.execute_reply.started":"2024-03-01T09:09:41.679283Z","shell.execute_reply":"2024-03-01T09:09:41.702879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Video Processnig","metadata":{}},{"cell_type":"code","source":"import urllib.request\n\naudio_url = \"https://github.com/AtharvaPawar456/SEM-8-Comps-FRCRCE/blob/main/Social-Media-Analytics-SMA/Labs/exp%20-%205/Cristiano%20Ronaldo%20Motivational%20Speech.mp4\"\noutput_file = \"video.mp4\"\n\n# Download the file\nurllib.request.urlretrieve(audio_url, output_file)\n\nprint(\"Audio file downloaded successfully.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:10:02.932968Z","iopub.execute_input":"2024-03-01T09:10:02.933285Z","iopub.status.idle":"2024-03-01T09:10:03.307257Z","shell.execute_reply.started":"2024-03-01T09:10:02.933261Z","shell.execute_reply":"2024-03-01T09:10:03.306245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install mediapipe opencv-python moviepy","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:12:32.608420Z","iopub.execute_input":"2024-03-01T09:12:32.608743Z","iopub.status.idle":"2024-03-01T09:12:41.979584Z","shell.execute_reply.started":"2024-03-01T09:12:32.608721Z","shell.execute_reply":"2024-03-01T09:12:41.978548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os\n\n# Function to extract frames from a video\ndef extract_frames(video_path, frame_interval=10):\n    cap = cv2.VideoCapture(video_path)\n    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n\n    output_folder = \"imgframes\"\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    frame_number = 0\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        if frame_number % (frame_rate * frame_interval) == 0:\n            frame_path = os.path.join(output_folder, f\"frame_{frame_number}.jpg\")\n            cv2.imwrite(frame_path, frame)\n            print(f\"Frame {frame_number} saved at {frame_path}\")\n\n        frame_number += 1\n\n    cap.release()\n\n# Specify the path to the video file\nvideofile = \"/kaggle/input/cristiano-ronaldo-motivational-speech/Cristiano Ronaldo Motivational Speech.mp4\"\n\n# Extract frames from the video\nextract_frames(videofile)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:25:40.133176Z","iopub.execute_input":"2024-03-01T09:25:40.133542Z","iopub.status.idle":"2024-03-01T09:25:48.696428Z","shell.execute_reply.started":"2024-03-01T09:25:40.133517Z","shell.execute_reply":"2024-03-01T09:25:48.695226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image, display\n\nframepathlist = [\"/kaggle/working/imgframes/frame_2250.jpg\", \"/kaggle/working/imgframes/frame_1750.jpg\", \"/kaggle/working/imgframes/frame_0.jpg\", \"/kaggle/working/imgframes/frame_750.jpg\", \"/kaggle/working/imgframes/frame_250.jpg\"]\n\nfor item in framepathlist:\n    display(Image(filename=item))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:28:33.363735Z","iopub.execute_input":"2024-03-01T09:28:33.364110Z","iopub.status.idle":"2024-03-01T09:28:33.384497Z","shell.execute_reply.started":"2024-03-01T09:28:33.364085Z","shell.execute_reply":"2024-03-01T09:28:33.383765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport mediapipe as mp\nimport os\n\n# Initialize Mediapipe Face Detection\nmp_face_detection = mp.solutions.face_detection\n\nfacedetected = []\n\ndef detect_faces(image_path, output_dir):\n    # Read the image\n    image = cv2.imread(image_path)\n    \n    # Convert the image to RGB\n    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \n    # Initialize the face detection model\n    face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.3)\n    \n    # Run face detection on the image\n    results = face_detection.process(rgb_image)\n    \n    # Draw bounding boxes around the faces\n    if results.detections:\n        for i, detection in enumerate(results.detections):\n            bboxC = detection.location_data.relative_bounding_box\n            ih, iw, _ = rgb_image.shape\n            bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n                   int(bboxC.width * iw), int(bboxC.height * ih)\n            \n            cv2.rectangle(image, bbox, (0, 255, 0), 2)\n            \n            # Save the image with bounding box\n            output_path = os.path.join(output_dir, f\"output_frame_{i}.jpg\")\n            cv2.imwrite(output_path, image)\n        facedetected.append(\"detected\")\n\n# List of frame paths\nframe_path_list = framepathlist\n\n# Output directory for images with bounding boxes\noutput_directory = \"/kaggle/working/output_frames\"\nif not os.path.exists(output_directory):\n    os.makedirs(output_directory)\n\n# Detect faces in each frame and save images with bounding boxes\nfor frame_path in frame_path_list:\n    detect_faces(frame_path, output_directory)\n\nfor item in facedetected:\n    print(f\"Face Detected in Image : {item}\")\ndisplay(Image(filename=\"/kaggle/working/output_frames/output_frame_0.jpg\"))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:35:21.489622Z","iopub.execute_input":"2024-03-01T09:35:21.490467Z","iopub.status.idle":"2024-03-01T09:35:21.615413Z","shell.execute_reply.started":"2024-03-01T09:35:21.490419Z","shell.execute_reply":"2024-03-01T09:35:21.614810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests\n\nAPI_URL = \"https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-base\"\nheaders = {\"Authorization\": \"Bearer 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\"}\n\ndef query(filename):\n    with open(filename, \"rb\") as f:\n        data = f.read()\n    response = requests.post(API_URL, headers=headers, data=data)\n    return response.json()\n\nframeDescription = []\nfor item in framepathlist:\n    output = query(item)\n    frameDescription.append(output)\n\n\n\nfor index, item in enumerate(framepathlist):\n    print(frameDescription[index])\n    display(Image(filename=item))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T09:41:15.977436Z","iopub.execute_input":"2024-03-01T09:41:15.977816Z","iopub.status.idle":"2024-03-01T09:41:22.618062Z","shell.execute_reply.started":"2024-03-01T09:41:15.977790Z","shell.execute_reply":"2024-03-01T09:41:22.617434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}